{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# evaluator_textonly_fixed.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import ast\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "from math import log2\n",
        "from typing import List, Dict, Tuple\n",
        "import difflib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------- utilities --------------------\n",
        "\n",
        "def _exists_any(paths: List[str]) -> str:\n",
        "    for p in paths:\n",
        "        if p and os.path.exists(p):\n",
        "            return p\n",
        "    return \"\"\n",
        "\n",
        "def _pick_col(df: pd.DataFrame, candidates: List[str]) -> str:\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise KeyError(f\"None of the columns {candidates} found. Available: {list(df.columns)}\")\n",
        "\n",
        "# -------------------- evaluator --------------------\n",
        "\n",
        "class TextOnlyRAGEvaluator:\n",
        "    \"\"\"\n",
        "    Text-only evaluator for RAG retrieval where gold supervision is *only* gold-text snippets.\n",
        "\n",
        "    Ground truth CSVs (both are used and merged by query):\n",
        "      - multi_file_retrieval_queries.csv\n",
        "      - single_file_retrieval_queries.csv  (or singlefile_retrieval_queries.csv)\n",
        "\n",
        "    Required columns (auto-detected names):\n",
        "      - query\n",
        "      - gold-text (or gold_text / gold / goldtext)  -> stored as raw_gold-text in outputs\n",
        "\n",
        "    Retrieval results JSON:\n",
        "      - rag_results.json with per-query 'results[*].match' (or 'text') and optional 'filename'.\n",
        "    \"\"\"\n",
        "\n",
        "    _SENT_SPLIT = re.compile(r'(?<=[\\.\\?\\!])\\s+')\n",
        "    _STOP = set(\"\"\"\n",
        "        a an the and or of in on to for from with as at by is are was were be been being\n",
        "        this that these those it its their his her we you they i vs v et al\n",
        "    \"\"\".split())\n",
        "    _EXT_RE = re.compile(r'\\.(pdf|txt|md|docx|pptx|html|htm|csv|json)$', re.I)\n",
        "\n",
        "    # ---------------- canonicalization ----------------\n",
        "    def _canon_query(self, s: str) -> str:\n",
        "        _PUNCT_TO_STRIP = string.punctuation + \"“”‘’´`•·•–—-\"  # add common unicode punct/dashes\n",
        "        _ZWSP_LIKE = \"\".join([\n",
        "            \"\\u200b\",  # zero width space\n",
        "            \"\\u200c\",  # zero width non-joiner\n",
        "            \"\\u200d\",  # zero width joiner\n",
        "            \"\\ufeff\",  # zero width no-break space (BOM)\n",
        "            \"\\u00a0\",  # non-breaking space\n",
        "        ])\n",
        "        # 1) Unicode normalize\n",
        "        s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "\n",
        "        # 2) Remove zero-width / NBSPs\n",
        "        s = s.translate({ord(c): None for c in _ZWSP_LIKE})\n",
        "\n",
        "        # 3) Normalize fancy quotes/dashes first, then strip all punctuation\n",
        "        s = (s.replace(\"“\", '\"').replace(\"”\", '\"')\n",
        "              .replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "              .replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"-\", \"-\"))\n",
        "        s = s.translate(str.maketrans(\"\", \"\", _PUNCT_TO_STRIP))\n",
        "\n",
        "        # 4) Lowercase and collapse whitespace\n",
        "        s = s.lower()\n",
        "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "        return s\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        multi_csv: str,\n",
        "        single_csv: str,\n",
        "        results_json: str,\n",
        "        out_dir: str = \"./eval_out\",\n",
        "        topk: List[int] = (1, 3, 5, 10),\n",
        "        query_col_candidates: List[str] = (\"query\", \"question\"),\n",
        "        gold_text_col_candidates: List[str] = (\"gold-text\", \"gold_text\", \"gold\", \"goldtext\"),\n",
        "    ):\n",
        "        # Allow path variants for single_csv\n",
        "        single_csv = _exists_any([single_csv, single_csv.replace(\"single_file_\", \"singlefile_\"),\n",
        "                                  single_csv.replace(\"singlefile_\", \"single_file_\")]) or single_csv\n",
        "\n",
        "        if not os.path.exists(multi_csv):\n",
        "            raise FileNotFoundError(f\"multi_csv not found: {multi_csv}\")\n",
        "        if not os.path.exists(single_csv):\n",
        "            print(f\"[warn] single_csv not found: {single_csv} — continuing with multi only.\")\n",
        "\n",
        "        self.multi_csv = multi_csv\n",
        "        self.single_csv = single_csv if os.path.exists(single_csv) else \"\"\n",
        "        self.results_json = results_json\n",
        "        self.out_dir = out_dir\n",
        "        self.topk = list(topk)\n",
        "\n",
        "        os.makedirs(self.out_dir, exist_ok=True)\n",
        "\n",
        "        # Load ground truth CSVs\n",
        "        self.multi_df = pd.read_csv(self.multi_csv)\n",
        "        if self.single_csv:\n",
        "            self.single_df = pd.read_csv(self.single_csv)\n",
        "        else:\n",
        "            self.single_df = pd.DataFrame(columns=list(self.multi_df.columns))\n",
        "\n",
        "        # Detect column names\n",
        "        self.query_col = _pick_col(self.multi_df if len(self.multi_df) else self.single_df, list(query_col_candidates))\n",
        "        self.gold_text_col = _pick_col(self.multi_df if len(self.multi_df) else self.single_df, list(gold_text_col_candidates))\n",
        "\n",
        "        # If the other split uses different casing, fix too\n",
        "        for df in (self.multi_df, self.single_df):\n",
        "            if self.query_col not in df.columns and len(df.columns):\n",
        "                alt = _pick_col(df, list(query_col_candidates))\n",
        "                df.rename(columns={alt: self.query_col}, inplace=True)\n",
        "            if self.gold_text_col not in df.columns and len(df.columns):\n",
        "                alt = _pick_col(df, list(gold_text_col_candidates))\n",
        "                df.rename(columns={alt: self.gold_text_col}, inplace=True)\n",
        "\n",
        "        # Load results\n",
        "        with open(self.results_json, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.results_data = json.load(f)\n",
        "\n",
        "        # Build gold lookup and query->split map (keys are canonicalized)\n",
        "        self.gold_lookup, self.query_split, self.display_lookup = self._build_gold_textonly()\n",
        "\n",
        "        # Build results map (canonicalized) and merge display names\n",
        "        self.results_map, results_display = self._build_results_map()\n",
        "        # Prefer gold display text when available; otherwise use results' original text\n",
        "        for k, disp in results_display.items():\n",
        "            self.display_lookup.setdefault(k, disp)\n",
        "\n",
        "    # --------------- parsing helpers ---------------\n",
        "    def _chunk_overlap_ratio(self, rt: str, gold_texts: List[str]) -> float:\n",
        "        \"\"\"\n",
        "        Portion of a retrieved chunk's characters that overlap with the BEST-matching gold snippet.\n",
        "        Uses character-level alignment (SequenceMatcher) on normalized strings.\n",
        "        Returns a value in [0, 1].\n",
        "        \"\"\"\n",
        "        rt_n = self._normalize_text(rt)\n",
        "        if not rt_n:\n",
        "            return 0.0\n",
        "\n",
        "        best = 0.0\n",
        "        for gt in gold_texts:\n",
        "            gt_n = self._normalize_text(gt)\n",
        "            if not gt_n:\n",
        "                continue\n",
        "            sm = difflib.SequenceMatcher(None, rt_n, gt_n, autojunk=False)\n",
        "            # Sum sizes for all exact-matching blocks\n",
        "            equal_chars = sum(m.size for m in sm.get_matching_blocks())\n",
        "            # Note: get_matching_blocks() ends with a size-0 sentinel—adds 0, safe to include.\n",
        "            ratio = equal_chars / max(1, len(rt_n))\n",
        "            if ratio > best:\n",
        "                best = ratio\n",
        "        return best\n",
        "\n",
        "\n",
        "    def chunk_overlap_metrics(self, retrieved_texts: List[str], gold_texts: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Computes the average per-chunk overlap ratio across all retrieved chunks for a query.\n",
        "        Returns:\n",
        "          - chunk_overlap: mean fraction of retrieved chunk content that overlaps with gold\n",
        "          - min_chunk_overlap / max_chunk_overlap: extremes across retrieved chunks\n",
        "          - chunk_overlap_count: number of retrieved chunks considered\n",
        "        \"\"\"\n",
        "        r_clean = [r for r in retrieved_texts if str(r).strip()]\n",
        "        g_clean = [g for g in gold_texts if str(g).strip()]\n",
        "\n",
        "        if not r_clean:\n",
        "            return {\n",
        "                'chunk_overlap': 0.0,\n",
        "                'min_chunk_overlap': 0.0,\n",
        "                'max_chunk_overlap': 0.0,\n",
        "                'chunk_overlap_count': 0,\n",
        "            }\n",
        "\n",
        "        overlaps = [self._chunk_overlap_ratio(rt, g_clean) for rt in r_clean]\n",
        "        return {\n",
        "            'chunk_overlap': float(np.mean(overlaps)) if overlaps else 0.0,\n",
        "            'min_chunk_overlap': float(np.min(overlaps)) if overlaps else 0.0,\n",
        "            'max_chunk_overlap': float(np.max(overlaps)) if overlaps else 0.0,\n",
        "            'chunk_overlap_count': int(len(overlaps)),\n",
        "        }\n",
        "\n",
        "\n",
        "    def _parse_gold_texts(self, v) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parse gold-text into a list. We do NOT split on commas.\n",
        "        Accepts: Python/JSON list/tuple, or '||' / ';' delimiters; else a single string.\n",
        "        \"\"\"\n",
        "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "            return []\n",
        "        s = str(v).strip()\n",
        "        if not s:\n",
        "            return []\n",
        "        # Python/JSON list-like\n",
        "        if (s.startswith('[') and s.endswith(']')) or (s.startswith('(') and s.endswith(')')):\n",
        "            try:\n",
        "                parsed = ast.literal_eval(s)\n",
        "                if isinstance(parsed, (list, tuple)):\n",
        "                    return [str(x) for x in parsed if str(x).strip()]\n",
        "                return [str(parsed)]\n",
        "            except Exception:\n",
        "                pass\n",
        "        # Explicit delimiters\n",
        "        if '||' in s:\n",
        "            return [t.strip() for t in s.split('||') if t.strip()]\n",
        "        if ';' in s:\n",
        "            return [t.strip() for t in s.split(';') if t.strip()]\n",
        "        return [s]\n",
        "\n",
        "    def _build_gold_for_df(self, df: pd.DataFrame) -> Tuple[Dict[str, Dict], Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          out: canon_query -> {\"texts\": [...], \"raw_text\": str}\n",
        "          display: canon_query -> first seen original query (for pretty printing)\n",
        "        \"\"\"\n",
        "        out: Dict[str, Dict] = {}\n",
        "        display: Dict[str, str] = {}\n",
        "        for _, row in df.iterrows():\n",
        "            q_orig = str(row[self.query_col])\n",
        "            q = self._canon_query(q_orig)\n",
        "            raw_txt = \"\" if row.get(self.gold_text_col) is None else str(row.get(self.gold_text_col))\n",
        "            texts = self._parse_gold_texts(row.get(self.gold_text_col, \"\"))\n",
        "\n",
        "            if q not in out:\n",
        "                out[q] = {\"texts\": [], \"raw_text\": raw_txt}\n",
        "                display[q] = q_orig  # preserve a human-readable version\n",
        "            else:\n",
        "                if not out[q].get(\"raw_text\"):\n",
        "                    out[q][\"raw_text\"] = raw_txt\n",
        "\n",
        "            out[q][\"texts\"].extend(texts)\n",
        "\n",
        "        # Dedup texts while preserving order\n",
        "        for qk in out:\n",
        "            seen, uniq = set(), []\n",
        "            for t in out[qk][\"texts\"]:\n",
        "                if t not in seen:\n",
        "                    seen.add(t)\n",
        "                    uniq.append(t)\n",
        "            out[qk][\"texts\"] = uniq\n",
        "        return out, display\n",
        "\n",
        "    def _build_gold_textonly(self) -> Tuple[Dict[str, Dict], Dict[str, str], Dict[str, str]]:\n",
        "        gold: Dict[str, Dict] = {}\n",
        "        split_map: Dict[str, str] = {}\n",
        "        display: Dict[str, str] = {}\n",
        "\n",
        "        multi, multi_disp = self._build_gold_for_df(self.multi_df)\n",
        "        single, single_disp = self._build_gold_for_df(self.single_df)\n",
        "\n",
        "        for q, v in multi.items():\n",
        "            gold[q] = {\"texts\": list(v[\"texts\"]), \"raw_text\": v.get(\"raw_text\", \"\")}\n",
        "            split_map[q] = \"multi\"\n",
        "            display[q] = multi_disp.get(q, q)\n",
        "\n",
        "        for q, v in single.items():\n",
        "            if q in gold:\n",
        "                # merge texts (dedup)\n",
        "                for t in v[\"texts\"]:\n",
        "                    if t not in gold[q][\"texts\"]:\n",
        "                        gold[q][\"texts\"].append(t)\n",
        "                if not gold[q].get(\"raw_text\"):\n",
        "                    gold[q][\"raw_text\"] = v.get(\"raw_text\", \"\")\n",
        "                split_map[q] = \"both\"\n",
        "                # keep existing display (prefer multi), or set if missing\n",
        "                display.setdefault(q, single_disp.get(q, q))\n",
        "            else:\n",
        "                gold[q] = {\"texts\": list(v[\"texts\"]), \"raw_text\": v.get(\"raw_text\", \"\")}\n",
        "                split_map[q] = \"single\"\n",
        "                display[q] = single_disp.get(q, q)\n",
        "\n",
        "        return gold, split_map, display\n",
        "\n",
        "    # --------------- results mapping ---------------\n",
        "\n",
        "    def _build_results_map(self) -> Tuple[Dict[str, Dict[str, List[str]]], Dict[str, str]]:\n",
        "        mapping: Dict[str, Dict[str, List[str]]] = {}\n",
        "        display: Dict[str, str] = {}\n",
        "        for item in self.results_data.get(\"queries\", []):\n",
        "            q_orig = str(item.get(\"query\", \"\"))\n",
        "            q = self._canon_query(q_orig)\n",
        "            docs, texts = [], []\n",
        "            for r in item.get(\"results\", []):\n",
        "                fn = r.get(\"filename\") or r.get(\"doc\") or r.get(\"document\") or r.get(\"id\") or \"\"\n",
        "                txt = r.get(\"match\") or r.get(\"text\") or \"\"\n",
        "                if fn:\n",
        "                    docs.append(str(fn))\n",
        "                if txt is not None and str(txt).strip():\n",
        "                    texts.append(str(txt))\n",
        "            # Dedup docs keeping order\n",
        "            seen, uniq_docs = set(), []\n",
        "            for d in docs:\n",
        "                if d not in seen:\n",
        "                    seen.add(d)\n",
        "                    uniq_docs.append(d)\n",
        "            mapping[q] = {\"docs\": uniq_docs, \"texts\": texts}\n",
        "            display.setdefault(q, q_orig)\n",
        "        return mapping, display\n",
        "\n",
        "    # --------------- normalization / tokenization ---------------\n",
        "\n",
        "    def _normalize_text(self, s: str) -> str:\n",
        "        return ' '.join(str(s).lower().split())\n",
        "\n",
        "    def _tok(self, text: str) -> List[str]:\n",
        "        t = str(text).lower()\n",
        "        t = t.translate(str.maketrans('', '', string.punctuation))\n",
        "        toks = [w for w in t.split() if w and w not in self._STOP]\n",
        "        return toks\n",
        "\n",
        "    def _split_sents(self, text: str) -> List[str]:\n",
        "        return [s.strip() for s in self._SENT_SPLIT.split(str(text).strip()) if s.strip()]\n",
        "\n",
        "    # --------------- robust overlap (tiered) ---------------\n",
        "\n",
        "    def _substring_containment(self, a: str, b: str) -> float:\n",
        "        \"\"\"\n",
        "        Character containment of a in b, after normalization.\n",
        "        returns |a| / |b| if a is substring of b, else 0.\n",
        "        We check both directions externally.\n",
        "        \"\"\"\n",
        "        a_n = self._normalize_text(a)\n",
        "        b_n = self._normalize_text(b)\n",
        "        if not a_n or not b_n:\n",
        "            return 0.0\n",
        "        if a_n in b_n:\n",
        "            return len(a_n) / max(1, len(b_n))\n",
        "        return 0.0\n",
        "\n",
        "    def _char_ngram_containment(self, a: str, b: str, n: int = 5) -> float:\n",
        "        \"\"\"\n",
        "        Character n-gram containment: |ngrams(a) ∩ ngrams(b)| / |ngrams(a)|.\n",
        "        Helps when wording changes slightly.\n",
        "        \"\"\"\n",
        "        a_n = self._normalize_text(a)\n",
        "        b_n = self._normalize_text(b)\n",
        "        if len(a_n) < n or len(b_n) < n:\n",
        "            return 0.0\n",
        "        def grams(s): return {s[i:i+n] for i in range(len(s)-n+1)}\n",
        "        A, B = grams(a_n), grams(b_n)\n",
        "        if not A:\n",
        "            return 0.0\n",
        "        return len(A & B) / len(A)\n",
        "\n",
        "    def _token_jaccard(self, a: str, b: str) -> float:\n",
        "        A, B = set(self._tok(a)), set(self._tok(b))\n",
        "        if not A or not B:\n",
        "            return 0.0\n",
        "        return len(A & B) / len(A | B)\n",
        "\n",
        "    def _match_score(self, gold: str, cand: str) -> float:\n",
        "        \"\"\"\n",
        "        Tiered score in [0,1]: max over\n",
        "         - exact/substring containment (both directions)\n",
        "         - token Jaccard\n",
        "         - char n-gram containment\n",
        "        \"\"\"\n",
        "        # substring containment (both directions)\n",
        "        s1 = self._substring_containment(gold, cand)\n",
        "        s2 = self._substring_containment(cand, gold)\n",
        "        # token Jaccard\n",
        "        sj = self._token_jaccard(gold, cand)\n",
        "        # char n-gram containment\n",
        "        sc = self._char_ngram_containment(gold, cand, n=5)\n",
        "        return max(s1, s2, sj, sc)\n",
        "\n",
        "    # --------------- text metrics ---------------\n",
        "\n",
        "    def text_overlap_metrics(\n",
        "        self,\n",
        "        retrieved_texts: List[str],\n",
        "        gold_texts: List[str],\n",
        "        recall_thresh: float = 0.30,     # gentler default\n",
        "        precision_thresh: float = 0.20,  # gentler default\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Use the tiered _match_score to compute:\n",
        "          - text_recall: fraction of gold snippets matched by any retrieved\n",
        "          - text_precision: fraction of retrieved snippets that match some gold\n",
        "        \"\"\"\n",
        "        if not gold_texts or all(not str(gt).strip() for gt in gold_texts):\n",
        "            return {'text_recall': 0.0, 'text_precision': 0.0, 'text_f1': 0.0,\n",
        "                    'num_gold_texts_matched': 0}\n",
        "\n",
        "        g_clean = [g for g in gold_texts if str(g).strip()]\n",
        "        r_clean = [r for r in retrieved_texts if str(r).strip()]\n",
        "\n",
        "        # Recall\n",
        "        found = 0\n",
        "        for g in g_clean:\n",
        "            if any(self._match_score(g, r) >= recall_thresh for r in r_clean):\n",
        "                found += 1\n",
        "        text_recall = found / len(g_clean) if g_clean else 0.0\n",
        "\n",
        "        # Precision\n",
        "        rel_ret = 0\n",
        "        for r in r_clean:\n",
        "            if any(self._match_score(r, g) >= precision_thresh for g in g_clean):\n",
        "                rel_ret += 1\n",
        "        text_precision = rel_ret / len(r_clean) if r_clean else 0.0\n",
        "\n",
        "        text_f1 = (2 * text_precision * text_recall / (text_precision + text_recall)\n",
        "                   if (text_precision + text_recall) > 0 else 0.0)\n",
        "\n",
        "        return {\n",
        "            'text_recall': text_recall,\n",
        "            'text_precision': text_precision,\n",
        "            'text_f1': text_f1,\n",
        "            'num_gold_texts_matched': found,\n",
        "        }\n",
        "\n",
        "    def context_sentence_metrics(self, gold_texts: List[str], retrieved_texts: List[str], thresh: float = 0.35):\n",
        "        \"\"\"Sentence-level context precision/recall/F1 using the same tiered _match_score.\"\"\"\n",
        "        gold_sents = [s for t in gold_texts for s in self._split_sents(t)]\n",
        "        ret_sents = [s for t in retrieved_texts for s in self._split_sents(t)]\n",
        "        if not gold_sents or not ret_sents:\n",
        "            return {'ctx_precision': 0.0, 'ctx_recall': 0.0, 'ctx_f1': 0.0}\n",
        "\n",
        "        matched_gold, matched_ret = set(), set()\n",
        "        for i, rt in enumerate(ret_sents):\n",
        "            for j, gt in enumerate(gold_sents):\n",
        "                if self._match_score(rt, gt) >= thresh:\n",
        "                    matched_gold.add(j)\n",
        "                    matched_ret.add(i)\n",
        "                    break\n",
        "\n",
        "        prec = len(matched_ret) / len(ret_sents) if ret_sents else 0.0\n",
        "        rec  = len(matched_gold) / len(gold_sents) if gold_sents else 0.0\n",
        "        f1   = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
        "        return {'ctx_precision': prec, 'ctx_recall': rec, 'ctx_f1': f1}\n",
        "\n",
        "    # --- Information Density (after context_sentence_metrics) ---\n",
        "    def information_density(self, retrieved_texts: List[str], gold_texts: List[str], thresh: float = 0.30) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Information Density: percent of retrieved *content length* that is relevant.\n",
        "        Counts characters of retrieved texts that match any gold snippet at the given threshold.\n",
        "        \"\"\"\n",
        "        if not retrieved_texts:\n",
        "            return {'information_density': 0.0, 'total_retrieved_chars': 0, 'relevant_chars': 0}\n",
        "\n",
        "        g_clean = [g for g in gold_texts if str(g).strip()]\n",
        "        r_clean = [r for r in retrieved_texts if str(r).strip()]\n",
        "\n",
        "        total_retrieved_chars = sum(len(self._normalize_text(rt)) for rt in r_clean)\n",
        "        relevant_chars = 0\n",
        "\n",
        "        for rt in r_clean:\n",
        "            rt_len = len(self._normalize_text(rt))\n",
        "            if any(self._match_score(rt, gt) >= thresh for gt in g_clean):\n",
        "                relevant_chars += rt_len\n",
        "\n",
        "        density = relevant_chars / total_retrieved_chars if total_retrieved_chars > 0 else 0.0\n",
        "        return {\n",
        "            'information_density': density,\n",
        "            'total_retrieved_chars': total_retrieved_chars,\n",
        "            'relevant_chars': relevant_chars\n",
        "        }\n",
        "\n",
        "\n",
        "    # rank-aware text metrics\n",
        "    def _text_supported_flags(self, retrieved_texts: List[str], gold_texts: List[str], thresh=0.30) -> List[int]:\n",
        "        g_clean = [g for g in gold_texts if str(g).strip()]\n",
        "        r_clean = [r for r in retrieved_texts if str(r).strip()]\n",
        "        flags = []\n",
        "        for r in r_clean:\n",
        "            hit = any(self._match_score(r, g) >= thresh for g in g_clean)\n",
        "            flags.append(1 if hit else 0)\n",
        "        return flags\n",
        "\n",
        "    def _text_recall_at_k(self, retrieved_texts: List[str], gold_texts: List[str], k: int, thresh=0.30) -> float:\n",
        "        g_clean = [g for g in gold_texts if str(g).strip()]\n",
        "        r_clean = [r for r in retrieved_texts[:k] if str(r).strip()]\n",
        "        if not g_clean:\n",
        "            return 0.0\n",
        "        found = 0\n",
        "        for g in g_clean:\n",
        "            if any(self._match_score(g, r) >= thresh for r in r_clean):\n",
        "                found += 1\n",
        "        return float(found / len(g_clean))\n",
        "\n",
        "   # --------------- per-query evaluation ---------------\n",
        "\n",
        "    def evaluate_query(self, canon_query_key: str) -> Dict:\n",
        "        # canon_query_key is already canonicalized in evaluate()\n",
        "        gold = self.gold_lookup.get(canon_query_key, {\"texts\": [], \"raw_text\": \"\"})\n",
        "        gtexts: List[str] = gold[\"texts\"]\n",
        "\n",
        "        res = self.results_map.get(canon_query_key, {\"docs\": [], \"texts\": []})\n",
        "        rdocs: List[str] = res[\"docs\"]\n",
        "        rtexts: List[str] = res[\"texts\"]\n",
        "\n",
        "        display_q = self.display_lookup.get(canon_query_key, canon_query_key)\n",
        "\n",
        "        out = {\n",
        "            \"query\": display_q,\n",
        "            \"split\": self.query_split.get(canon_query_key, \"unknown\"),\n",
        "            \"raw_gold-text\": gold.get(\"raw_text\", \"\"),\n",
        "            \"num_gold_texts\": len(gtexts),\n",
        "            \"num_retrieved\": len(rdocs),\n",
        "            \"retrieved_docs\": rtexts[:10],\n",
        "        }\n",
        "\n",
        "        # Text overlap (robust)\n",
        "        out.update(self.text_overlap_metrics(rtexts, gtexts))\n",
        "\n",
        "        # Sentence-level context metrics\n",
        "        out.update(self.context_sentence_metrics(gtexts, rtexts))\n",
        "\n",
        "        out.update(self.chunk_overlap_metrics(rtexts, gtexts))\n",
        "\n",
        "        # Rank-aware text metrics\n",
        "        flags = self._text_supported_flags(rtexts, gtexts, thresh=0.30)\n",
        "        for k in (1, 3):\n",
        "            if k in self.topk:\n",
        "                top_flags = flags[:k]\n",
        "                out[f\"text_supported@{k}\"] = float(sum(top_flags) / k) if k > 0 and top_flags else 0.0\n",
        "                out[f\"text_recall@{k}\"] = self._text_recall_at_k(rtexts, gtexts, k, thresh=0.30)\n",
        "\n",
        "        return out\n",
        "\n",
        "    # --------------- evaluate all / aggregate ---------------\n",
        "\n",
        "    def evaluate(self) -> Tuple[Dict, pd.DataFrame]:\n",
        "        gold_qs = set(self.gold_lookup.keys())\n",
        "        res_qs = set(self.results_map.keys())\n",
        "        all_qs = sorted(list(gold_qs | res_qs))  # canonicalized keys\n",
        "\n",
        "        rows = [self.evaluate_query(qk) for qk in all_qs]\n",
        "        df = pd.DataFrame(rows)\n",
        "        agg = self._aggregate(df)\n",
        "        return agg, df\n",
        "\n",
        "    def _aggregate(self, df: pd.DataFrame) -> Dict:\n",
        "        if df.empty:\n",
        "            return {\"total_queries\": 0}\n",
        "\n",
        "        agg: Dict[str, float] = {\n",
        "            \"total_queries\": int(df.shape[0]),\n",
        "            \"queries_with_multiple_texts\": int((df[\"num_gold_texts\"] > 1).sum()),\n",
        "            \"avg_gold_texts_per_query\": float(df[\"num_gold_texts\"].mean()),\n",
        "        }\n",
        "\n",
        "        to_stat = [\n",
        "            \"text_recall\", \"text_precision\", \"text_f1\",\n",
        "            \"ctx_precision\", \"ctx_recall\", \"ctx_f1\",\n",
        "            \"chunk_overlap\",                # NEW\n",
        "            \"min_chunk_overlap\",            # optional, keep if you want distro stats\n",
        "            \"max_chunk_overlap\",            # optional\n",
        "            *(f\"text_supported@{k}\" for k in self.topk),\n",
        "            *(f\"text_recall@{k}\" for k in self.topk),\n",
        "        ]\n",
        "\n",
        "        for m in to_stat:\n",
        "            vals = df[m].fillna(0.0).astype(float).values if m in df else np.array([0.0])\n",
        "            agg[f\"mean_{m}\"] = float(np.mean(vals))\n",
        "            agg[f\"std_{m}\"]  = float(np.std(vals))\n",
        "            agg[f\"min_{m}\"]  = float(np.min(vals))\n",
        "            agg[f\"max_{m}\"]  = float(np.max(vals))\n",
        "\n",
        "        for split in [\"multi\", \"single\", \"both\"]:\n",
        "            sdf = df[df[\"split\"] == split]\n",
        "            agg[f\"{split}_queries\"] = int(sdf.shape[0])\n",
        "            for m in [\"text_f1\", \"ctx_f1\", \"text_recall@3\", \"text_recall@5\"]:\n",
        "                agg[f\"{split}_mean_{m}\"] = float(sdf[m].fillna(0.0).mean()) if m in sdf else 0.0\n",
        "        return agg\n",
        "\n",
        "    # --------------- outputs ---------------\n",
        "\n",
        "    def write_outputs(self, agg: Dict, df: pd.DataFrame):\n",
        "        os.makedirs(self.out_dir, exist_ok=True)\n",
        "        per_query_csv = os.path.join(self.out_dir, \"per_query_metrics.csv\")\n",
        "        df.to_csv(per_query_csv, index=False)\n",
        "\n",
        "        overall_json = os.path.join(self.out_dir, \"summary.json\")\n",
        "        with open(overall_json, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(agg, f, indent=2)\n",
        "\n",
        "        report_path = os.path.join(self.out_dir, \"report.txt\")\n",
        "        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"=\" * 90 + \"\\n\")\n",
        "            f.write(\"CS RAG (TEXT-ONLY) RETRIEVAL EVALUATION — robust matching\\n\")\n",
        "            f.write(\"=\" * 90 + \"\\n\\n\")\n",
        "            f.write(\"DATASET STATS\\n\")\n",
        "            f.write(\"-\" * 90 + \"\\n\")\n",
        "            f.write(f\"Total Queries: {agg['total_queries']}\\n\")\n",
        "            f.write(f\"Queries with Multiple Gold Texts: {agg['queries_with_multiple_texts']}\\n\")\n",
        "            f.write(f\"Avg Gold Texts / Query: {agg['avg_gold_texts_per_query']:.2f}\\n\\n\")\n",
        "\n",
        "            f.write(\"GLOBAL METRICS (means ± stdev)\\n\")\n",
        "            f.write(\"-\" * 90 + \"\\n\")\n",
        "            for m in [\"text_recall\", \"text_precision\", \"text_f1\",\n",
        "                \"ctx_precision\", \"ctx_recall\", \"ctx_f1\",\n",
        "                \"chunk_overlap\",\n",
        "                \"text_supported@3\", \"text_recall@3\"]:\n",
        "                if f\"mean_{m}\" in agg:\n",
        "                    f.write(f\"{m:>18}: {agg[f'mean_{m}']:.4f} ± {agg[f'std_{m}']:.4f} \"\n",
        "                            f\"(min {agg[f'min_{m}']:.4f}, max {agg[f'max_{m}']:.4f})\\n\")\n",
        "\n",
        "            f.write(\"\\nSPLIT-SPECIFIC (means)\\n\")\n",
        "            f.write(\"-\" * 90 + \"\\n\")\n",
        "            for split in [\"multi\", \"single\", \"both\"]:\n",
        "                f.write(f\"{split.upper():<6} | n={agg.get(f'{split}_queries',0):<3d} | \"\n",
        "                        f\"tF1={agg.get(f'{split}_mean_text_f1',0.0):.4f}  \"\n",
        "                        f\"cF1={agg.get(f'{split}_mean_ctx_f1',0.0):.4f}  \"\n",
        "                        f\"tR@3={agg.get(f'{split}_mean_text_recall@3',0.0):.4f}\\n \")\n",
        "        print(f\"[✓] Wrote:\\n - {per_query_csv}\\n - {overall_json}\\n - {report_path}\")\n",
        "\n",
        "# ------------- Colab-friendly wrapper -------------\n",
        "\n",
        "def evaluate_cs_rag_textonly(\n",
        "    multi_csv=\"/mnt/data/multi_file_retrieval_queries.csv\",\n",
        "    single_csv=\"/mnt/data/single_file_retrieval_queries.csv\",  # auto-detects singlefile_ variant\n",
        "    results_json=\"/mnt/data/rag_results.json\",\n",
        "    out_dir=\"./eval_out_textonly\",\n",
        "    topk=(1, 3),\n",
        "    return_df=True,\n",
        "):\n",
        "    ev = TextOnlyRAGEvaluator(\n",
        "        multi_csv=multi_csv,\n",
        "        single_csv=single_csv,\n",
        "        results_json=results_json,\n",
        "        out_dir=out_dir,\n",
        "        topk=list(topk),\n",
        "    )\n",
        "    agg, df = ev.evaluate()\n",
        "    ev.write_outputs(agg, df)\n",
        "    if return_df:\n",
        "        try:\n",
        "            from IPython.display import display\n",
        "            print(\"=== Per-query metrics (head) ===\")\n",
        "            display(df.head(10))\n",
        "        except Exception:\n",
        "            print(df.head(10))\n",
        "    print(\"\\n=== Summary (Text-Only) ===\")\n",
        "    print(f\"TextF1: {agg.get('mean_text_f1', 0.0):.4f}  \"\n",
        "        f\"CtxF1: {agg.get('mean_ctx_f1', 0.0):.4f}  \"\n",
        "        f\"tR@3: {agg.get('mean_text_recall@3', 0.0):.4f}  \"\n",
        "        f\"ChunkOverlap: {agg.get('mean_chunk_overlap', 0.0):.4f}\")\n",
        "    print(f\"\\nWrote outputs to: {out_dir}\\n - per_query_metrics.csv\\n - summary.json\\n - report.txt\")\n",
        "    return agg, df\n"
      ],
      "metadata": {
        "id": "_oO3OMkVihon"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agg, df = evaluate_cs_rag_textonly(\n",
        "    multi_csv=\"/content/multi_file_retrieval_queries.csv\",\n",
        "    single_csv=\"/content/single_file_retrieval_queries.csv\",\n",
        "    results_json=\"/content/rag_results.json\",\n",
        "    out_dir=\"./eval_out\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JcWN4GASLIgH",
        "outputId": "aaf36e6a-6da0-41a2-e53b-60062069602f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Wrote:\n",
            " - ./eval_out/per_query_metrics.csv\n",
            " - ./eval_out/summary.json\n",
            " - ./eval_out/report.txt\n",
            "=== Per-query metrics (head) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               query   split  \\\n",
              "0  Explain the importance of ImageNet in the work...   multi   \n",
              "1  How does auto-differentiation work in these fr...  single   \n",
              "2  What are FlashMLA, DeepEP, and DeepGEMM, and w...  single   \n",
              "3  What are the challenges of theoretical distrib...   multi   \n",
              "4  What are the three core components of the Tiny...  single   \n",
              "5  What are the trade-offs between simple post-tr...   multi   \n",
              "6  What does “IO-aware” mean in the context of Fl...  single   \n",
              "7  What is internal covariate shift, and how does...  single   \n",
              "8  What is NVIDIA GPU Confidential Computing (CC)...  single   \n",
              "9  What is the difference between torch.disttibut...   multi   \n",
              "\n",
              "                                       raw_gold-text  num_gold_texts  \\\n",
              "0  ('We trained a large, deep convolutional neura...               2   \n",
              "1  TensorFlow is an interface for expressing mach...               1   \n",
              "2  Accelerating Transformer Layers•FlashMLA  (rel...               1   \n",
              "3  ('Challenge 1: Stage Partitioning•How to parti...               4   \n",
              "4  The system is organized around three core comp...               1   \n",
              "5  ('8CUDA APIs for Half Precision•Using lower pr...               3   \n",
              "6  In this paper, we argue that a missing princip...               1   \n",
              "7  We deﬁne Internal Covariate Shift as the chang...               1   \n",
              "8  NVIDIA CC ensures the confidentiality and inte...               1   \n",
              "9  ('While promising for scaling, pipelining is o...               2   \n",
              "\n",
              "   num_retrieved                                     retrieved_docs  \\\n",
              "0              3  [and then use the same scaling coefﬁcients for...   \n",
              "1              3  [operations are implemented in low- latency C+...   \n",
              "2              3  [Operators that can be reused in Other Network...   \n",
              "3              3  [All rights reserved. Amazon Confidential and ...   \n",
              "4              3  [training. These works emphasize that carefull...   \n",
              "5              3  [compared with accurate -but-expensive methods...   \n",
              "6              3  [we plot of the validation perplexity througho...   \n",
              "7              3  [of internal covariate shift on train- ing, an...   \n",
              "8              3  [the GPU, while “c” and “d” denote ciphertexts...   \n",
              "9              3  [performs runtime shape/dtype inference automa...   \n",
              "\n",
              "   text_recall  text_precision  text_f1  num_gold_texts_matched  ...  \\\n",
              "0         0.00        0.000000      0.0                       0  ...   \n",
              "1         1.00        0.333333      0.5                       1  ...   \n",
              "2         1.00        0.333333      0.5                       1  ...   \n",
              "3         0.25        0.000000      0.0                       1  ...   \n",
              "4         0.00        0.333333      0.0                       0  ...   \n",
              "5         0.00        0.000000      0.0                       0  ...   \n",
              "6         0.00        0.000000      0.0                       0  ...   \n",
              "7         1.00        0.000000      0.0                       1  ...   \n",
              "8         1.00        0.000000      0.0                       1  ...   \n",
              "9         0.00        0.000000      0.0                       0  ...   \n",
              "\n",
              "   ctx_recall    ctx_f1  chunk_overlap  min_chunk_overlap  max_chunk_overlap  \\\n",
              "0    0.500000  0.086957       0.135727           0.061417           0.173633   \n",
              "1    1.000000  0.222222       0.317728           0.210674           0.501282   \n",
              "2    1.000000  0.380952       0.328882           0.087483           0.668919   \n",
              "3    0.153846  0.137931       0.154604           0.138282           0.163328   \n",
              "4    0.250000  0.111111       0.186808           0.169492           0.207447   \n",
              "5    0.000000  0.000000       0.140531           0.104065           0.161654   \n",
              "6    0.000000  0.000000       0.138549           0.105183           0.157560   \n",
              "7    0.000000  0.000000       0.135878           0.114504           0.170772   \n",
              "8    0.500000  0.090909       0.148254           0.147563           0.149593   \n",
              "9    0.000000  0.000000       0.114029           0.062078           0.163142   \n",
              "\n",
              "   chunk_overlap_count  text_supported@1  text_recall@1  text_supported@3  \\\n",
              "0                    3               0.0           0.00          0.000000   \n",
              "1                    3               0.0           0.00          0.333333   \n",
              "2                    3               1.0           1.00          0.333333   \n",
              "3                    3               0.0           0.25          0.000000   \n",
              "4                    3               1.0           0.00          0.333333   \n",
              "5                    3               0.0           0.00          0.000000   \n",
              "6                    3               0.0           0.00          0.000000   \n",
              "7                    3               0.0           1.00          0.000000   \n",
              "8                    3               0.0           1.00          0.000000   \n",
              "9                    3               0.0           0.00          0.000000   \n",
              "\n",
              "   text_recall@3  \n",
              "0           0.00  \n",
              "1           1.00  \n",
              "2           1.00  \n",
              "3           0.25  \n",
              "4           0.00  \n",
              "5           0.00  \n",
              "6           0.00  \n",
              "7           1.00  \n",
              "8           1.00  \n",
              "9           0.00  \n",
              "\n",
              "[10 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79964ddb-98a5-49e7-bc45-410eabff4ef6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>split</th>\n",
              "      <th>raw_gold-text</th>\n",
              "      <th>num_gold_texts</th>\n",
              "      <th>num_retrieved</th>\n",
              "      <th>retrieved_docs</th>\n",
              "      <th>text_recall</th>\n",
              "      <th>text_precision</th>\n",
              "      <th>text_f1</th>\n",
              "      <th>num_gold_texts_matched</th>\n",
              "      <th>...</th>\n",
              "      <th>ctx_recall</th>\n",
              "      <th>ctx_f1</th>\n",
              "      <th>chunk_overlap</th>\n",
              "      <th>min_chunk_overlap</th>\n",
              "      <th>max_chunk_overlap</th>\n",
              "      <th>chunk_overlap_count</th>\n",
              "      <th>text_supported@1</th>\n",
              "      <th>text_recall@1</th>\n",
              "      <th>text_supported@3</th>\n",
              "      <th>text_recall@3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explain the importance of ImageNet in the work...</td>\n",
              "      <td>multi</td>\n",
              "      <td>('We trained a large, deep convolutional neura...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>[and then use the same scaling coefﬁcients for...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.135727</td>\n",
              "      <td>0.061417</td>\n",
              "      <td>0.173633</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does auto-differentiation work in these fr...</td>\n",
              "      <td>single</td>\n",
              "      <td>TensorFlow is an interface for expressing mach...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[operations are implemented in low- latency C+...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.317728</td>\n",
              "      <td>0.210674</td>\n",
              "      <td>0.501282</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are FlashMLA, DeepEP, and DeepGEMM, and w...</td>\n",
              "      <td>single</td>\n",
              "      <td>Accelerating Transformer Layers•FlashMLA  (rel...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[Operators that can be reused in Other Network...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.328882</td>\n",
              "      <td>0.087483</td>\n",
              "      <td>0.668919</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the challenges of theoretical distrib...</td>\n",
              "      <td>multi</td>\n",
              "      <td>('Challenge 1: Stage Partitioning•How to parti...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>[All rights reserved. Amazon Confidential and ...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.154604</td>\n",
              "      <td>0.138282</td>\n",
              "      <td>0.163328</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the three core components of the Tiny...</td>\n",
              "      <td>single</td>\n",
              "      <td>The system is organized around three core comp...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[training. These works emphasize that carefull...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.186808</td>\n",
              "      <td>0.169492</td>\n",
              "      <td>0.207447</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What are the trade-offs between simple post-tr...</td>\n",
              "      <td>multi</td>\n",
              "      <td>('8CUDA APIs for Half Precision•Using lower pr...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[compared with accurate -but-expensive methods...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140531</td>\n",
              "      <td>0.104065</td>\n",
              "      <td>0.161654</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What does “IO-aware” mean in the context of Fl...</td>\n",
              "      <td>single</td>\n",
              "      <td>In this paper, we argue that a missing princip...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[we plot of the validation perplexity througho...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138549</td>\n",
              "      <td>0.105183</td>\n",
              "      <td>0.157560</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is internal covariate shift, and how does...</td>\n",
              "      <td>single</td>\n",
              "      <td>We deﬁne Internal Covariate Shift as the chang...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[of internal covariate shift on train- ing, an...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.135878</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.170772</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is NVIDIA GPU Confidential Computing (CC)...</td>\n",
              "      <td>single</td>\n",
              "      <td>NVIDIA CC ensures the confidentiality and inte...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[the GPU, while “c” and “d” denote ciphertexts...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.148254</td>\n",
              "      <td>0.147563</td>\n",
              "      <td>0.149593</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is the difference between torch.disttibut...</td>\n",
              "      <td>multi</td>\n",
              "      <td>('While promising for scaling, pipelining is o...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>[performs runtime shape/dtype inference automa...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114029</td>\n",
              "      <td>0.062078</td>\n",
              "      <td>0.163142</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79964ddb-98a5-49e7-bc45-410eabff4ef6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79964ddb-98a5-49e7-bc45-410eabff4ef6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79964ddb-98a5-49e7-bc45-410eabff4ef6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-977d8ef3-3826-459d-bc56-61e4cfe19c6b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-977d8ef3-3826-459d-bc56-61e4cfe19c6b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-977d8ef3-3826-459d-bc56-61e4cfe19c6b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Summary (Text-Only) ===\n",
            "TextF1: 0.2200  CtxF1: 0.1414  tR@3: 0.5500  ChunkOverlap: 0.1876\n",
            "\n",
            "Wrote outputs to: ./eval_out\n",
            " - per_query_metrics.csv\n",
            " - summary.json\n",
            " - report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIftlvy53PxN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d63668",
   "metadata": {},
   "source": [
    "### BASELINE-1 RAG [BM25 Algorithm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee49a9",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91bf5f",
   "metadata": {},
   "source": [
    "Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d59f4ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"all_pdfs\"\n",
    "pdfs = {}\n",
    "for root, _, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                pdf = f.read()\n",
    "                pdf = re.sub(r'\\n\\s*\\n', '\\n', pdf)\n",
    "                pdf = re.sub(r'\\s+', ' ', pdf)\n",
    "                pdfs[file_path] = pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a439f",
   "metadata": {},
   "source": [
    "Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "per_word = {}\n",
    "total_length = 0\n",
    "for path_file, pdf_text_val in pdfs.items():\n",
    "\n",
    "    #total length\n",
    "    pdf_text_val = pdf_text_val.lower()\n",
    "    words = re.findall(r'\\w+', pdf_text_val)\n",
    "    total_length += len(words)\n",
    "    per_word[path_file] = len(words)\n",
    "    \n",
    "    #frequency counter\n",
    "    word_freq = Counter(words)\n",
    "    for word, freq in word_freq.items():\n",
    "        if word not in index:\n",
    "            index[word] = {}\n",
    "        index[word][path_file] = freq\n",
    "\n",
    "avg_val = total_length / len(pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0968f2",
   "metadata": {},
   "source": [
    "BM25 Algorithm (Best Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(term, path_file, index, per_word, avg_val,k1 = 1.5, b = 0.75):\n",
    "    freq_u = index[term][path_file]\n",
    "    size = per_word[path_file]\n",
    "    normalized_length = size / avg_val\n",
    "    \n",
    "    N = len(per_word) \n",
    "    term_total_ = len(index[term])\n",
    "    indx_freq = math.log((N - term_total_ + 0.5) / (term_total_ + 0.5) + 1)\n",
    "    \n",
    "    numr = freq_u * (k1 + 1)\n",
    "    denom = freq_u + k1 * (1 - b + b * normalized_length)\n",
    "    return indx_freq * numr / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784163fe",
   "metadata": {},
   "source": [
    "Extract Content from PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(contnt, query_terms, window_size = 100):\n",
    "    words_from_pdf = contnt.split()\n",
    "    pos_term = []\n",
    "    \n",
    "    for i, word in enumerate(words_from_pdf):\n",
    "        if any(term in word.lower() for term in query_terms):\n",
    "            pos_term.append(i)\n",
    "    \n",
    "    best_start = 0\n",
    "    maxi = 0\n",
    "    for i in range(len(words_from_pdf) - window_size):\n",
    "        window_end = i + window_size\n",
    "        terms_in_window = sum(1 for pos in pos_term if i <= pos < window_end)\n",
    "        if terms_in_window > maxi:\n",
    "            maxi = terms_in_window\n",
    "            best_start = i\n",
    "    \n",
    "    text_starting  = max(0, best_start)\n",
    "    end_of_document_text = min(len(words_from_pdf), best_start + window_size)\n",
    "    tota_matched_text_document = ' '.join(words_from_pdf[text_starting :end_of_document_text])\n",
    "    return tota_matched_text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2421d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_matched_text(query, pdfs, index, per_word, avg_val, top_k = 3):\n",
    "    query = query.lower()\n",
    "    query_terms = re.findall(r'\\w+', query)\n",
    "    doc_scores= {}\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term in index:\n",
    "            for path_file in index[term]:\n",
    "                score = bm25(term, path_file, index, per_word, avg_val)\n",
    "                if path_file not in doc_scores:\n",
    "                    doc_scores[path_file] = 0.0\n",
    "                doc_scores[path_file] += score\n",
    "\n",
    "    scored_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for path_file, score in scored_docs:\n",
    "        if score > 0:\n",
    "            tota_matched_text_document = get_text(\n",
    "                pdfs[path_file],\n",
    "                query_terms\n",
    "            )\n",
    "            results.append((path_file, score, tota_matched_text_document))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfdbf74",
   "metadata": {},
   "source": [
    "Queries load from Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe938d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_queries.json', 'r') as f:\n",
    "    queries = json.load(f)['queries']\n",
    "results = []\n",
    "for qry in queries:\n",
    "    query = qry['query']\n",
    "    docs_match_and_text = finding_matched_text(query, pdfs, index, per_word, avg_val)\n",
    "    result_json = {\n",
    "        \"query\": query,\n",
    "        \"results\": []\n",
    "    }\n",
    "    if docs_match_and_text:\n",
    "        for path_file, score, match in docs_match_and_text:\n",
    "            filename = os.path.basename(path_file)\n",
    "            result_json[\"results\"].append({\n",
    "                \"filename\": filename,\n",
    "                \"match\": match\n",
    "            })\n",
    "    results.append(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac86a0",
   "metadata": {},
   "source": [
    "Append to the Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d820d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rag_baseline1.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump({\"queries\": results}, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

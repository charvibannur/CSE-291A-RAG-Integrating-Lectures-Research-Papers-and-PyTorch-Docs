torch.monitor
Created On: Jan 12, 2022 | Last Updated On: Jun 11, 2025
This module is a prototype release, and its interfaces and functionality may change without
warning in future PyTorch releases.
torch.monitor  provides an interface for logging events and counters from PyTorch.
The stat interfaces are designed to be used for tracking high level metrics that are periodically
logged out to be used for monitoring system performance. Since the stats aggregate with a specific
window size you can log to them from critical loops with minimal performance impact.
For more infrequent events or values such as loss, accuracy, usage tracking the event interface can
be directly used.
Event handlers can be registered to handle the events and pass them to an external event sink.
API Reference
class torch.monitor. Aggregation
Members:These are types of aggregations that can be used to accumulate stats.
VALUE :
VALUE returns the last value to be added.
MEAN :
MEAN computes the arithmetic mean of all the added values.Warning ⚠
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:07 PM torch.monitor — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/monitor.html 1/6property  name
class torch.monitor. Stat
Stat is used to compute summary statistics in a performant way over fixed intervals. Stat logs
the statistics as an Event once every window_size  duration. When the window closes the stats
are logged via the event handlers as a torch.monitor.Stat  event.
window_size  should be set to something relatively high to avoid a huge number of events
being logged. Ex: 60s. Stat uses millisecond precision.
If max_samples  is set, the stat will cap the number of samples per window by discarding add
calls once max_samples  adds have occurred. If itʼs not set, all add calls during the window will
be included. This is an optional field to make aggregations more directly comparable across
windows when the number of samples might vary.
When the Stat is destructed it will log any remaining data even if the window hasnʼt elapsed.
__init__ (self: torch._C._monitor.Stat , name: str, aggregations :
list[torch._C._monitor.Aggregation ], window_size : datetime.timedelta ,
max_samples : int = 9223372036854775807 ) → None
Constructs the Stat.
add (self: torch._C._monitor.Stat , v: float ) → NoneCOUNT :
COUNT returns the total number of added values.
SUM :
SUM returns the sum of the added values.
MAX :
MAX returns the max of the added values.
MIN :
MIN returns the min of the added values.
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:07 PM torch.monitor — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/monitor.html 2/6Adds a value to the stat to be aggregated according to the configured stat type and
aggregations.
property  count
Number of data points that have currently been collected. Resets once the event has been
logged.
get (self: torch._C._monitor.Stat ) → dict[torch._C._monitor.Aggregation ,
float]
Returns the current value of the stat, primarily for testing purposes. If the stat has logged
and no additional values have been added this will be zero.
property  name
The name of the stat that was set during creation.
class torch.monitor. data_value_t
data_value_t is one of str, float, int, bool.
class torch.monitor. Event
Event represents a specific typed event to be logged. This can represent high-level data points
such as loss or accuracy per epoch or more low-level aggregations such as through the Stats
provided through this library.
All Events of the same type should have the same name so downstream handlers can correctly
process them.
__init__ (self: torch._C._monitor.Event , name: str, timestamp :
datetime.datetime , data: dict[str, data_value_t ] ) → None
Constructs the Event.
property  dataTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:07 PM torch.monitor — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/monitor.html 3/6The structured data contained within the Event.
property  name
The name of the Event.
property  timestamp
The timestamp when the Event happened.
class torch.monitor. EventHandlerHandle
EventHandlerHandle is a wrapper type returned by register_event_handler  used to
unregister the handler via unregister_event_handler . This cannot be directly initialized.
torch.monitor. log_event (event: torch._C._monitor.Event ) → None
log_event logs the specified event to all of the registered event handlers. Itʼs up to the event
handlers to log the event out to the corresponding event sink.
If there are no event handlers registered this method is a no-op.
torch.monitor. register_event_handler (callback :
Callable [[torch._C._monitor.Event ], None] ) →
torch._C._monitor.EventHandlerHandle
register_event_handler registers a callback to be called whenever an event is logged via
log_event . These handlers should avoid blocking the main thread since that may interfere
with training as they run during the log_event  call.
torch.monitor. unregister_event_handler (handler:
torch._C._monitor.EventHandlerHandle ) → None
unregister_event_handler unregisters the EventHandlerHandle  returned after calling
register_event_handler . After this returns the event handler will no longer receive events.To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:07 PM torch.monitor — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/monitor.html 4/6[source]
[source]class torch.monitor. TensorboardEventHandler (writer )
TensorboardEventHandler is an event handler that will write known events to the provided
SummaryWriter.
This currently only supports torch.monitor.Stat  events which are logged as scalars.
Example
__init__ (writer )
Constructs the TensorboardEventHandler .
Previous
torch.linalg.ldl_solveNext
torch.signalRate this Page★★★★★
© Copyright PyTorch Contributors.
Built with the PyData Sphinx Theme 0.15.4.>>> from torch.utils.tensorboard  import SummaryWriter
>>> from torch.monitor  import TensorboardEventHandler , register_event_handler
>>> writer = SummaryWriter ("log_dir" )
>>> register_event_handler (TensorboardEventHandler (writer))
Send Feedback
Docs
Access comprehensive
developer documentation
for PyTorchTutorials
Get in-depth tutorials for
beginners and advanced
developersResources
Find development
resources and get your
questions answered
View Docs View Tutorials View Resources
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:07 PM torch.monitor — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/monitor.html 5/6Stay in touch for updates, event info, and the latest news
First Name* Last Name* Email*
Select Country* SUBMIT
By submitting this form, I consent to receive marketing emails from the LF and its projects
regarding their events, training, research, developments, and related announcements. I understand
that I can unsubscribe at any time using the links in the footers of the emails I receive. Privacy
Policy.
© PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has
registered trademarks and uses trademarks. For more information, including terms of use, privacy
policy, and trademark usage, please see our Policies page. Trademark Usage. Privacy Policy.
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:07 PM torch.monitor — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/monitor.html 6/6
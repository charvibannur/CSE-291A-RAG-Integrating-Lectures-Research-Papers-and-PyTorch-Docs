torch.special
Created On: Mar 04, 2021 | Last Updated On: Jun 18, 2025
The torch.special module, modeled after SciPyʼs special module.
Functions
torch.special. airy_ai (input, *, out=None ) → Tensor
Airy function .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. bessel_j0 (input, *, out=None ) → Tensor
Bessel function of the first kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. bessel_j1 (input, *, out=None ) → Tensor
Bessel function of the first kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:Aiinput( )
0
1
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 1/27out (Tensor, optional) – the output tensor.
torch.special. bessel_y0 (input, *, out=None ) → Tensor
Bessel function of the second kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. bessel_y1 (input, *, out=None ) → Tensor
Bessel function of the second kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. chebyshev_polynomial_t (input, n, *, out=None ) → Tensor
Chebyshev polynomial of the first kind .
If ,  is returned. If ,  is returned. If  or  the recursion:
is evaluated. Otherwise, the explicit trigonometric formula:
is evaluated.
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.0
1
T  (input ) n
n=01 n=1input n<6∣input ∣>1
T  (input )= n+1 2×input × T  (input )− n T  (input ) n−1
T  (input )= n cos( n×arccos( x))
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 2/27Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. chebyshev_polynomial_u (input, n, *, out=None ) → Tensor
Chebyshev polynomial of the second kind .
If ,  is returned. If ,  is returned. If  or , the
recursion:
is evaluated. Otherwise, the explicit trigonometric formula:
is evaluated.
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. chebyshev_polynomial_v (input, n, *, out=None ) → Tensor
Chebyshev polynomial of the third kind .
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.U  (input ) n
n=01 n=12×input n<6∣input ∣>1
U  (input )= n+1 2×input × U  (input )− n U (input ) n−1
 sin(arccos(input ))sin(( n+1)×arccos(input ))
V  (input )n∗
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 3/27torch.special. chebyshev_polynomial_w (input, n, *, out=None ) → Tensor
Chebyshev polynomial of the fourth kind .
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. digamma (input, *, out=None ) → Tensor
Computes the logarithmic derivative of the gamma function on input.
Parameters:
input (Tensor) – the tensor to compute the digamma function on
Keyword Arguments:
out (Tensor, optional) – the output tensor.
This function is similar to SciPyʼs scipy.special.digamma.
From PyTorch 1.8 onwards, the digamma function returns -Inf for 0. Previously it
returned NaN for 0.
Example:W (input ) n∗
ϝ( x)=  lnΓ x=d xd(())  Γ( x)Γ( x)′
>>> a = torch.tensor([1, 0.5])
>>> torch.special.digamma(a)
tensor([-0.5772, -1.9635])Note 
Note 
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 4/27torch.special. entr (input, *, out=None ) → Tensor
Computes the entropy on input (as defined below), elementwise.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. erf (input, *, out=None ) → Tensor
Computes the error function of input. The error function is defined as follows:
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example: entr(x)=   
⎩⎨⎧− x∗ln( x)
0
−∞x>0
x=0.0
x<0(1)
>>> a = torch.arange(-0.5, 1, 0.5)
>>> a
tensor([-0.5000,  0.0000,  0.5000])
>>> torch.special.entr(a)
tensor([  -inf, 0.0000, 0.3466])
erf( x)=   e d t
 π2∫
0x
− t2
>>> torch.special.erf(torch.tensor([0, -1., 10.]))
tensor([ 0.0000, -0.8427,  1.0000])To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 5/27torch.special. erfc (input, *, out=None ) → Tensor
Computes the complementary error function of input. The complementary error function is
defined as follows:
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. erfcx (input, *, out=None ) → Tensor
Computes the scaled complementary error function for each element of input. The scaled
complementary error function is defined as follows:
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. erfinv (input, *, out=None ) → Tensorerfc( x)=1−   e d t
 π2∫
0x
− t2
>>> torch.special.erfc(torch.tensor([0, -1., 10.]))
tensor([ 1.0000, 1.8427,  0.0000])
erfcx( x)= eerfc( x)x2
>>> torch.special.erfcx(torch.tensor([0, -1., 10.]))
tensor([ 1.0000, 5.0090, 0.0561])To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 6/27Computes the inverse error function of input. The inverse error function is defined in the
range  as:
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. exp2 (input, *, out=None ) → Tensor
Computes the base two exponential function of input.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. expit (input, *, out=None ) → Tensor
Computes the expit (also known as the logistic sigmoid function) of the elements of input.(−1,1)
erfinv(erf( x))= x
>>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))
tensor([ 0.0000,  0.4769,    -inf])
y  = i2x  i
>>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))
tensor([ 1.,  2.,  8., 16.])
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 7/27Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. expm1 (input, *, out=None ) → Tensor
Computes the exponential of the elements minus 1 of input.
This function provides greater precision than exp(x) - 1 for small values of x.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:out = i 1+ e−input  i1
>>> t = torch.randn(4)
>>> t
tensor([ 0.9213,  1.0887, -0.8858, -1.7683])
>>> torch.special.expit(t)
tensor([ 0.7153,  0.7481,  0.2920,  0.1458])
y  = i e−x  i1
>>> torch.special.expm1(torch.tensor([0, math.log(2.)]))
tensor([ 0.,  1.])Note 
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 8/27torch.special. gammainc (input, other, *, out=None ) → Tensor
Computes the regularized lower incomplete gamma function:
where both  and  are weakly positive and at least one is strictly positive. If both
are zero or either is negative then .  in the equation above is the gamma
function,
See torch.special.gammaincc()  and torch.special.gammaln()  for related functions.
Supports broadcasting to a common shape and float inputs.
The backward pass with respect to input is not yet supported. Please open an issue
on PyTorchʼs Github to request it.
Parameters:
input (Tensor) – the first non-negative input tensor
other (Tensor) – the second non-negative input tensor
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:out  = i  t e d tΓ(input  ) i1∫
0other  i
input  −1i − t
input i other i
out= inanΓ(⋅)
Γ(input  )=i t e d t. ∫
0∞
(input  −1)i − t
>>> a1 = torch.tensor([4.0])
>>> a2 = torch.tensor([3.0, 4.0, 5.0])
>>> a = torch.special.gammaincc (a1, a2)
tensor([0.3528, 0.5665, 0.7350])
tensor([0.3528, 0.5665, 0.7350])
>>> b = torch.special.gammainc (a1, a2) + torch.special.gammaincc (a1, a2)
tensor([1., 1., 1.])Note 
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 9/27torch.special. gammaincc (input, other, *, out=None ) → Tensor
Computes the regularized upper incomplete gamma function:
where both  and  are weakly positive and at least one is strictly positive. If both
are zero or either is negative then .  in the equation above is the gamma
function,
See torch.special.gammainc()  and torch.special.gammaln()  for related functions.
Supports broadcasting to a common shape and float inputs.
The backward pass with respect to input is not yet supported. Please open an issue
on PyTorchʼs Github to request it.
Parameters:
input (Tensor) – the first non-negative input tensor
other (Tensor) – the second non-negative input tensor
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:out  = i  t e d tΓ(input  )i1∫
other i∞
input−1i − t
input  i other i
out= inanΓ(⋅)
Γ(input  )=i t e d t. ∫
0∞
(input  −1)i − t
>>> a1 = torch.tensor([4.0])
>>> a2 = torch.tensor([3.0, 4.0, 5.0])
>>> a = torch.special.gammaincc (a1, a2)
tensor([0.6472, 0.4335, 0.2650])
>>> b = torch.special.gammainc (a1, a2) + torch.special.gammaincc (a1, a2)
tensor([1., 1., 1.])Note 
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 10/27torch.special. gammaln (input, *, out=None ) → Tensor
Computes the natural logarithm of the absolute value of the gamma function on input.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. hermite_polynomial_h (input, n, *, out=None ) → Tensor
Physicistʼs Hermite polynomial .
If ,  is returned. If ,  is returned. Otherwise, the recursion:
is evaluated.
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. hermite_polynomial_he (input, n, *, out=None ) → Tensor
Probabilistʼs Hermite polynomial .
If ,  is returned. If ,  is returned. Otherwise, the recursion:out  = ilnΓ(∣input  ∣)i
>>> a = torch.arange(0.5, 2, 0.5)
>>> torch.special.gammaln(a)
tensor([ 0.5724,  0.0000, -0.1208])
H  (input ) n
n=01 n=1input
H  (input )= n+1 2×input × H  (input )− n H  (input ) n−1
H e (input ) n
n=01 n=1inputTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 11/27is evaluated.
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. i0 (input, *, out=None ) → Tensor
Computes the zeroth order modified Bessel function of the first kind for each element of
input.
Parameters:
input (Tensor) – the input tensor
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. i0e (input, *, out=None ) → Tensor
Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as
defined below) for each element of input.H e  (input )= n+1 2×input × H e  (input )− n H e  (input ) n−1
out  = i I  (input  )= 0 i  
k=0∑∞
( k!)2(input  /4)i2 k
>>> torch.i0(torch.arange(5, dtype=torch.float32))
tensor([ 1.0000,  1.2661,  2.2796,  4.8808, 11.3019])
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 12/27Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. i1 (input, *, out=None ) → Tensor
Computes the first order modified Bessel function of the first kind (as defined below) for each
element of input.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. i1e (input, *, out=None ) → Tensor
Computes the exponentially scaled first order modified Bessel function of the first kind (as
defined below) for each element of input.out  = iexp(−∣ x∣)∗ i0( x)=exp(−∣ x∣)∗   
k=0∑∞
( k!)2(input  /4)i2 k
>>> torch.special.i0e(torch.arange(5, dtype=torch.float32))
tensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])
out  = i ∗2(input  )i
  
k=0∑∞
( k!)∗( k+1)!(input  /4)i2 k
>>> torch.special.i1(torch.arange(5, dtype=torch.float32))
tensor([0.0000, 0.5652, 1.5906, 3.9534, 9.7595])
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 13/27Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. laguerre_polynomial_l (input, n, *, out=None ) → Tensor
Laguerre polynomial .
If ,  is returned. If ,  is returned. Otherwise, the recursion:
is evaluated.
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. legendre_polynomial_p (input, n, *, out=None ) → Tensor
Legendre polynomial .
If ,  is returned. If ,  is returned. Otherwise, the recursion:out  = iexp(−∣ x∣)∗ i1( x)=exp(−∣ x∣)∗  ∗2(input  )i
  
k=0∑∞
( k!)∗( k+1)!(input  /4)i2 k
>>> torch.special.i1e(torch.arange(5, dtype=torch.float32))
tensor([0.0000, 0.2079, 0.2153, 0.1968, 0.1788])
L  (input ) n
n=01 n=1input
L  (input )= n+1 2×input × L  (input )− n L  (input ) n−1
P (input ) n
n=01 n=1inputTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 14/27is evaluated.
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. log1p (input, *, out=None ) → Tensor
Alias for torch.log1p() .
torch.special. log_ndtr (input, *, out=None ) → Tensor
Computes the log of the area under the standard Gaussian probability density function,
integrated from minus infinity to input, elementwise.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. log_softmax (input, dim, *, dtype=None ) → Tensor
Computes softmax followed by a logarithm.P  (input )= n+1 2×input × P  (input )− n P  (input ) n−1
log_ndtr( x)=log   e d t (
 2 π1∫
−∞x
−  t212)
>>> torch.special.log_ndtr (torch.tensor([-3., -2, -1, 0, 1, 2, 3]))
tensor([-6.6077 -3.7832 -1.841  -0.6931 -0.1728 -0.023  -0.0014])
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 15/27While mathematically equivalent to log(softmax(x)), doing these two operations separately is
slower and numerically unstable. This function is computed as:
Parameters:
input (Tensor) – input
dim (int) – A dimension along which log_softmax will be computed.
dtype (torch.dtype , optional) – the desired data type of returned tensor. If specified
the input tensor is cast to dtype before the operation is performed. This is useful for
preventing data type overflows. Default: None.
Example:
torch.special. logit (input, eps=None, *, out=None ) → Tensor
Returns a new tensor with the logit of the elements of input. input is clamped to [eps, 1 -
eps] when eps is not None. When eps is None and input < 0 or input > 1, the function will
yields NaN.
Parameters:
input (Tensor) – the input tensor.
eps (float, optional) – the epsilon for input clamp bound. Default: Nonelog_softmax( x  )= i log  (
 exp( x  ) ∑j jexp( x  ) i)
>>> t = torch.ones(2, 2)
>>> torch.special.log_softmax (t, 0)
tensor([[-0.6931, -0.6931],
        [-0.6931, -0.6931]])
  y  i
z  i=ln( )1− z  iz  i
=   
⎩⎨⎧ x  i
eps
x  i
1−epsif eps is None
if  x  <eps i
if eps≤ x  ≤1−eps i
if  x  >1−eps i(2)
(3)
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 16/27Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. logsumexp (input, dim, keepdim=False, *, out=None )
Alias for torch.logsumexp() .
torch.special. modified_bessel_i0 (input, *, out=None ) → Tensor
Modified Bessel function of the first kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. modified_bessel_i1 (input, *, out=None ) → Tensor
Modified Bessel function of the first kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. modified_bessel_k0 (input, *, out=None ) → Tensor
Modified Bessel function of the second kind of order .>>> a = torch.rand(5)
>>> a
tensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])
>>> torch.special.logit(a, eps=1e-6)
tensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])
0
1
0To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 17/27Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. modified_bessel_k1 (input, *, out=None ) → Tensor
Modified Bessel function of the second kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. multigammaln (input, p, *, out=None ) → Tensor
Computes the multivariate log-gamma function with dimension  element-wise, given by
where  and  is the Gamma function.
All elements must be greater than , otherwise the behavior is undefined.
Parameters:
input (Tensor) – the tensor to compute the multivariate log-gamma function
p (int) – the number of dimensions
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:1
p
log(Γ  ( a))= p C+ logΓ a−  
i=1∑p
((2i−1))
C=log( π)⋅  4p( p−1)Γ(−)
 2p−1
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 18/27torch.special. ndtr (input, *, out=None ) → Tensor
Computes the area under the standard Gaussian probability density function, integrated from
minus infinity to input, elementwise.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. ndtri (input, *, out=None ) → Tensor
Computes the argument, x, for which the area under the Gaussian probability density function
(integrated from minus infinity to x) is equal to input, elementwise.
Also known as quantile function for Normal Distribution.>>> a = torch.empty(2, 3).uniform_ (1, 2)
>>> a
tensor([[1.6835, 1.8474, 1.1929],
        [1.0475, 1.7162, 1.4180]])
>>> torch.special.multigammaln (a, 2)
tensor([[0.3928, 0.4007, 0.7586],
        [1.0311, 0.3901, 0.5049]])
ndtr( x)=   e d t
 2 π1∫
−∞x
−  t212
>>> torch.special.ndtr(torch.tensor([-3., -2, -1, 0, 1, 2, 3]))
tensor([0.0013, 0.0228, 0.1587, 0.5000, 0.8413, 0.9772, 0.9987])
ndtri( p)=  erf(2 p− 2−11)
Note To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 19/27Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. polygamma (n, input, *, out=None ) → Tensor
Computes the  derivative of the digamma function on input.  is called the order of
the polygamma function.
This function is implemented only for nonnegative integers .
Parameters:
n (int) – the order of the polygamma function
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:>>> torch.special.ndtri(torch.tensor([0, 0.25, 0.5, 0.75, 1]))
tensor([   -inf, -0.6745,  0.0000,  0.6745,     inf])
nt hn≥0
ψ( x)=( n)
 ψ( x)d x( n)d( n)
n≥0Note 
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 20/27torch.special. psi (input, *, out=None ) → Tensor
Alias for torch.special.digamma() .
torch.special. round (input, *, out=None ) → Tensor
Alias for torch.round() .
torch.special. scaled_modified_bessel_k0 (input, *, out=None ) → Tensor
Scaled modified Bessel function of the second kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. scaled_modified_bessel_k1 (input, *, out=None ) → Tensor
Scaled modified Bessel function of the second kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.>>> a = torch.tensor([1, 0.5])
>>> torch.special.polygamma (1, a)
tensor([1.64493, 4.9348])
>>> torch.special.polygamma (2, a)
tensor([ -2.4041, -16.8288])
>>> torch.special.polygamma (3, a)
tensor([ 6.4939, 97.4091])
>>> torch.special.polygamma (4, a)
tensor([ -24.8863, -771.4742])
0
1
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 21/27torch.special. shifted_chebyshev_polynomial_t (input, n, *, out=None ) →
Tensor
Chebyshev polynomial of the first kind .
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. shifted_chebyshev_polynomial_u (input, n, *, out=None ) →
Tensor
Chebyshev polynomial of the second kind .
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. shifted_chebyshev_polynomial_v (input, n, *, out=None ) →
Tensor
Chebyshev polynomial of the third kind .
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. shifted_chebyshev_polynomial_w (input, n, *, out=None ) →
TensorT  (input )n∗
U(input )n∗
V  (input )n∗
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 22/27Chebyshev polynomial of the fourth kind .
Parameters:
input (Tensor) – the input tensor.
n (Tensor) – Degree of the polynomial.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. sinc (input, *, out=None ) → Tensor
Computes the normalized sinc of input.
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. softmax (input, dim, *, dtype=None ) → Tensor
Computes the softmax function.
Softmax is defined as:W  (input )n∗
out = i  {1,
sin( πinput  )/( πinput  ),i iif input  =0i
otherwise
>>> t = torch.randn(4)
>>> t
tensor([ 0.2252, -0.2948,  1.0267, -1.1566])
>>> torch.special.sinc(t)
tensor([ 0.9186,  0.8631, -0.0259, -0.1300])
Softmax( x  )= i 
 exp( x  ) ∑j jexp( x ) iTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 23/27It is applied to all slices along dim, and will re-scale them so that the elements lie in the range
[0, 1] and sum to 1.
Parameters:
input (Tensor) – input
dim (int) – A dimension along which softmax will be computed.
dtype (torch.dtype , optional) – the desired data type of returned tensor. If specified
the input tensor is cast to dtype before the operation is performed. This is useful for
preventing data type overflows. Default: None.
Examples::
torch.special. spherical_bessel_j0 (input, *, out=None ) → Tensor
Spherical Bessel function of the first kind of order .
Parameters:
input (Tensor) – the input tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
torch.special. xlog1py (input, other, *, out=None ) → Tensor
Computes input * log1p(other)  with the following cases.
Similar to SciPyʼs scipy.special.xlog1py.
Parameters:>>> t = torch.ones(2, 2)
>>> torch.special.softmax(t, 0)
tensor([[0.5000, 0.5000],
        [0.5000, 0.5000]])
0
out  = i   
⎩⎨⎧NaN
0
input  ∗log1p(other  )i iif other  =NaN i
if input  =0.0 and other  !=NaNi i
otherwiseTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 24/27input (Number or Tensor) – Multiplier
other (Number or Tensor) – Argument
At least one of input or other must be a tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. xlogy (input, other, *, out=None ) → Tensor
Computes input * log(other)  with the following cases.
Similar to SciPyʼs scipy.special.xlogy.
Parameters:
input (Number or Tensor) – Multiplier
other (Number or Tensor) – Argument>>> x = torch.zeros(5,)
>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])
>>> torch.special.xlog1py(x, y)
tensor([0., 0., 0., 0., nan])
>>> x = torch.tensor([1, 2, 3])
>>> y = torch.tensor([3, 2, 1])
>>> torch.special.xlog1py(x, y)
tensor([1.3863, 2.1972, 2.0794])
>>> torch.special.xlog1py(x, 4)
tensor([1.6094, 3.2189, 4.8283])
>>> torch.special.xlog1py(2, y)
tensor([2.7726, 2.1972, 1.3863])
out  = i   
⎩⎨⎧NaN
0
input ∗log(other ) i iif other  =NaN i
if input  =0.0 i
otherwiseNote 
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 25/27At least one of input or other must be a tensor.
Keyword Arguments:
out (Tensor, optional) – the output tensor.
Example:
torch.special. zeta (input, other, *, out=None ) → Tensor
Computes the Hurwitz zeta function, elementwise.
Parameters:
input (Tensor) – the input tensor corresponding to x.
other (Tensor) – the input tensor corresponding to q.
TheRiemannzetafunctioncorrespondstothecasewhenq1Previous
torch.signal.windows.nuttallNext
torch.overridesRate this Page★★★★★
© Copyright PyTorch Contributors.
Built with the PyData Sphinx Theme 0.15.4.>>> x = torch.zeros(5,)
>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])
>>> torch.special.xlogy(x, y)
tensor([0., 0., 0., 0., nan])
>>> x = torch.tensor([1, 2, 3])
>>> y = torch.tensor([3, 2, 1])
>>> torch.special.xlogy(x, y)
tensor([1.0986, 1.3863, 0.0000])
>>> torch.special.xlogy(x, 4)
tensor([1.3863, 2.7726, 4.1589])
>>> torch.special.xlogy(2, y)
tensor([2.1972, 1.3863, 0.0000])
ζ( x, q)=  
k=0∑∞
( k+ q)x1
Send FeedbackNote 
Note 
DocsTutorialsResourcesTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 26/27Access comprehensive
developer documentation
for PyTorchGet in-depth tutorials for
beginners and advanced
developersFind development
resources and get your
questions answered
View Docs View Tutorials View Resources
Stay in touch for updates, event info, and the latest news
First Name* Last Name* Email*
Select Country* SUBMIT
By submitting this form, I consent to receive marketing emails from the LF and its projects
regarding their events, training, research, developments, and related announcements. I understand
that I can unsubscribe at any time using the links in the footers of the emails I receive. Privacy
Policy.
© PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has
registered trademarks and uses trademarks. For more information, including terms of use, privacy
policy, and trademark usage, please see our Policies page. Trademark Usage. Privacy Policy.
To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or
navigating, you agree to allow our usage of cookies. As the current maintainers of this site,
Facebookʼs Cookies Policy applies. Learn more, including about available controls: Cookies
Policy.10/10/25, 3:03 PM torch.special — PyTorch 2.8 documentation
https://docs.pytorch.org/docs/stable/special.html 27/27